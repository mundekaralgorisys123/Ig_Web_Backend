import time
import re
import os
from datetime import datetime
import requests
from playwright.sync_api import sync_playwright, TimeoutError, expect
from openpyxl import Workbook
from openpyxl.drawing.image import Image
from bs4 import BeautifulSoup
from flask import Flask
import uuid
import logging
import base64
from utils import get_public_ip, log_event, sanitize_filename
from database import insert_into_db, create_table
from dotenv import load_dotenv
from playwright.sync_api import Page, TimeoutError, Error
from limit_checker import update_product_count
import time
import random
# Load environment variables from .env file
load_dotenv()
# Get proxy URL from .env, if available
PROXY_URL = os.getenv("PROXY_URL")


app = Flask(__name__)

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
EXCEL_DATA_PATH = os.path.join(app.root_path, 'static', 'ExcelData')
IMAGE_SAVE_PATH = os.path.join(BASE_DIR, 'static', 'Images')


def close_email_popup(page):
    """Repeatedly close the email sign-up popup if it appears."""
    popup_close_selectors = [
        "#bx-close-inside-2803374",
        "[data-click='close']",
        ".bx-close-link",
        ".bx-close-inside",
    ]

    for _ in range(5):  # Try multiple times in case the popup reappears
        for selector in popup_close_selectors:
            try:
                popup = page.query_selector(selector)
                if popup and popup.is_visible():
                    print(f"üîç Popup detected: '{selector}'. Attempting to close it...")

                    # Corrected Playwright evaluate syntax
                    page.evaluate("(selector) => document.querySelector(selector)?.click()", selector)
                    page.wait_for_timeout(1000)  # Allow time for popup to close
                    print("‚úÖ Popup closed successfully.")
                    return  # Exit after closing
            except TimeoutError:
                pass
            except Exception as e:
                print(f"‚ùå Error closing popup '{selector}': {e}")

    print("üìå No popups found or could not be closed.")

def random_delay(min_sec=1, max_sec=3):
    """Introduce a random delay to mimic human-like behavior."""
    time.sleep(random.uniform(min_sec, max_sec))

def scroll_and_wait(page: Page):
    """Scroll down to load lazy-loaded products."""
    previous_height = page.evaluate("document.body.scrollHeight")
    page.evaluate("window.scrollBy(0, document.body.scrollHeight);")
    time.sleep(2)  # Allow time for content to load
    new_height = page.evaluate("document.body.scrollHeight")
    return new_height > previous_height  # Returns True if more content is loaded

def scroll_and_load_products(page: Page, max_pages: int):
    """Scroll and click 'Load More' button until all products are loaded or max pages are reached."""
    close_email_popup(page)  # Handle popups initially

    # =========================
    # Scroll to load products on the first page
    # =========================
    scroll_attempts = 0
    max_scroll_attempts = 10
    while scroll_attempts < max_scroll_attempts and scroll_and_wait(page):
        scroll_attempts += 1
        random_delay(1, 3)

    # =========================
    # Click "Load More" Dynamically
    # =========================
    load_more_clicks = 0
    while load_more_clicks < (max_pages - 1):  # First page is already loaded
        try:
            load_more_button = page.query_selector(".load-more-button-uk")
            if load_more_button and load_more_button.is_visible():
                print(f"üîÑ Clicking 'Load More' button... (Page {load_more_clicks + 2})")
                load_more_button.click()
                random_delay(3, 5)
                load_more_clicks += 1

                # Scroll again after clicking Load More
                scroll_attempts = 0
                while scroll_attempts < max_scroll_attempts and scroll_and_wait(page):
                    scroll_attempts += 1
                    random_delay(1, 3)
            else:
                print("‚ùå No visible 'Load More' button. Exiting loop.")
                break
        except Exception as e:
            print(f"‚ùå 'Load More' button not found or error occurred: {e}")
            break

    print(f"üéâ Completed loading products up to page {load_more_clicks + 1}/{max_pages}.")

def handle_kay(url, max_pages):
    """Handles the scraping process for the given URL."""
    logging.info(f"Scraping started for: {url} with max_pages: {max_pages}")
    print("====================== IN =======================================================")

    with sync_playwright() as p:
        browser = p.chromium.connect_over_cdp(PROXY_URL)  # Connect via proxy
        page = browser.new_page()
        print("Opening page...")

        # Open the page and wait for content to load
        page.goto(url, timeout=120000, wait_until="domcontentloaded")

        # Close popups if found
        close_email_popup(page)

        # Scroll to load products
        scroll_attempts = 0
        max_scroll_attempts = 10
        while scroll_attempts < max_scroll_attempts and scroll_and_wait(page):
            scroll_attempts += 1
            random_delay(1, 3)

        # Click "Load More" Dynamically
        load_more_clicks = 0
        while load_more_clicks < (max_pages - 1):  # First page is already loaded
            try:
                load_more_button = page.query_selector(".load-more-button-uk")
                
                if load_more_button and load_more_button.is_visible():
                    print(f"üîÑ Clicking 'Load More' button... (Page {load_more_clicks + 2})")
                    
                    # Try JavaScript click in case it's blocked
                    page.evaluate("(btn) => btn.click()", load_more_button)
                    
                    load_more_clicks += 1
                    random_delay(3, 5)

                    # Scroll again to load more products
                    for _ in range(max_scroll_attempts):
                        if not scroll_and_wait(page):
                            break
                        random_delay(1, 3)
                else:
                    print("‚ùå 'Load More' button not found or blocked. Retrying after closing popups...")
                    close_email_popup(page)
                    random_delay(2, 4)
                    continue

            except Exception as e:
                print(f"‚ö†Ô∏è Error clicking 'Load More': {e}")
                break

        # Extract content using BeautifulSoup
        content = BeautifulSoup(page.content(), 'html.parser')
        print("Extracting product data...")

        title_tag = content.find('title')
        page_title = title_tag.get_text(strip=True) if title_tag else "No title found"
        print(f"Page title: {page_title}")

        product_wrapper = content.find('div', class_='product-scroll-wrapper')
        products = product_wrapper.find_all('div', class_='product-item') if product_wrapper else []
        print(f"‚úÖ Products scraped: {len(products)}")

        # Close browser
        browser.close()

    return save_to_excel(products, page_title)



def save_to_excel(products, page_title):
    # Ensure the Excel data folder exists.
    if not os.path.exists(EXCEL_DATA_PATH):
        os.makedirs(EXCEL_DATA_PATH)

    # Create a timestamp for file naming and image folder.
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    image_folder = os.path.join(IMAGE_SAVE_PATH, timestamp)
    os.makedirs(image_folder, exist_ok=True)

    # Create the Excel workbook.
    wb = Workbook()
    sheet = wb.active
    sheet.title = "Products"
    headers = ["Current Date", "Header", "Product Name", "Image", "Kt", "Price", "Total Dia wt", "Time", "ImagePath"]
    sheet.append(headers)

    current_date = datetime.now().strftime("%Y-%m-%d")
    time_only = datetime.now().strftime("%H.%M")
    # create_table()  # Ensure the database table exists

    row_num = 2  # Start after header row

    # Process each product one-by-one.
    for product in products:
        # Extract product name.
        product_name_tag = product.find('h2', class_='name product-tile-description')
        product_name = product_name_tag.get_text(strip=True) if product_name_tag else "N/A"

        # Extract price.
        price_tag = product.find('div', class_='price')
        price = price_tag.text.strip() if price_tag else "N/A"

        # Extract image URL.
        images = product.find_all('img')
        product_urls = [img['src'] for img in images if img.get('src', '').startswith('https://')]
        image_url = product_urls[0] if product_urls else "N/A"

        # Extract Gold Type (e.g., "14K Yellow Gold").
        gold_type_pattern = r"\b\d+K\s+\w+\s+\w+\b"
        gold_type_match = re.search(gold_type_pattern, product_name)
        kt = gold_type_match.group() if gold_type_match else "Not found"

        # Extract Diamond Weight (e.g., "1/2 ct tw").
        diamond_weight_pattern = r"\d+[-/]?\d*/?\d*\s*ct\s*tw"
        diamond_weight_match = re.search(diamond_weight_pattern, product_name)
        diamond_weight = diamond_weight_match.group() if diamond_weight_match else "N/A"

        unique_id = str(uuid.uuid4())

        # Download and save the image (if available).
        image_path = "N/A"
        image_full_path = None
        if image_url != "N/A":
            try:
                img_data = requests.get(image_url).content
                image_filename = f"{sanitize_filename(product_name)}_{timestamp}.jpg"
                image_full_path = os.path.join(image_folder, image_filename)
                with open(image_full_path, "wb") as f:
                    f.write(img_data)
                # Store the relative image path.
                image_path = os.path.join("Images", timestamp, image_filename)
            except Exception as e:
                log_event(f"Error downloading image for {product_name}: {e}")

        # Write product data into the Excel file.
        sheet.append([current_date, page_title, product_name, None, kt, price, diamond_weight, time_only, image_url])
        
        # Insert the image into Excel (if downloaded successfully).
        if image_full_path and os.path.exists(image_full_path):
            try:
                img = Image(image_full_path)
                img.width, img.height = 100, 100
                sheet.add_image(img, f"D{row_num}")
            except Exception as e:
                log_event(f"Error adding image to Excel for {product_name}: {e}")
        
        sheet.row_dimensions[row_num].height = 100
        row_num += 1

        # Immediately insert the record into the database.
        record = (unique_id, current_date, page_title, product_name, image_path, kt, price, diamond_weight)
        insert_into_db([record])

    # Save the Excel file.
    # filename = 'Products_Playwright.xlsx'
    filename = f"kay_{current_date}_{time_only}.xlsx"
    file_path = os.path.join(EXCEL_DATA_PATH, filename)
    wb.save(file_path)
    log_event(f"Data saved to {file_path}")

    # Encode the Excel file in base64 for further use if needed.
    with open(file_path, "rb") as file:
        base64_encoded = base64.b64encode(file.read()).decode("utf-8")
    print("====================== OUT =======================================================")
    
    products_fetched = len(products)
    # Update the product count.
    update_product_count(products_fetched)
        
    return base64_encoded, filename, file_path